{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erwanlbv/OrientalismProject/blob/master/Importing_clm_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJVweiwr6e1t",
        "outputId": "d6060c24-4967-4148-fc5f-6df5bde1f7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Y4z-ZeUvXT",
        "outputId": "c88c9c7a-7327-4b26-ad81-388ff39bc00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'OrientalismProject'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 6), reused 24 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Erwanlbv/OrientalismProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRZgV26I6k0g",
        "outputId": "30bb3c3b-1da3-4a97-914b-736f0885919c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/transformers/examples/pytorch/language-modeling/transformers\n"
          ]
        }
      ],
      "source": [
        "cd transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEaKhV4m607f",
        "outputId": "be268214-55ce-4a61-c55f-206a867cd052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/transformers/examples/pytorch/language-modeling/transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3231485 sha256=d34a840cfc9c99bad438f28eaab81ae47ea43b4371a9ac895603d1e91c9a4b69\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yase8cvo/wheels/0a/32/59/1aa56aaf1728a7a766e782c97c893f2cc9904bdaab5d0dbda6\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.13.0.dev0\n",
            "    Uninstalling transformers-4.13.0.dev0:\n",
            "      Successfully uninstalled transformers-4.13.0.dev0\n",
            "Successfully installed transformers-4.13.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy6Uh9VV64QX",
        "outputId": "83f27cd7-25a9-4213-ecf2-748da2e90b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'examples/pytorch/language-modeling/'\n",
            "/content/transformers/examples/pytorch/language-modeling/transformers/examples/pytorch/language-modeling\n"
          ]
        }
      ],
      "source": [
        "cd examples/pytorch/language-modeling/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oexNKrw7cnE",
        "outputId": "7909ccad-8aac-4a06-cee6-ad0932b05d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2018.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "8ef3e3c038374166940afa698d5c98a7",
            "4151f8bc9ffa4be1accae3030131df29",
            "33b9e9b72f0349eb94aba5e8ccc2abe2",
            "409d74549cfc411c9208241493fcb78a",
            "22bb77f37463433986f3e0a3c4c8c3cc",
            "76cab0b69cb7469fa8a9521332e7b0af",
            "bb6ffdb0b81b443681d2e8194d03d569",
            "e8343355c15e4719aefa092cca8c4330",
            "a2b1157acf544098abf2bf951d330539",
            "6ae36ae1334641cb919fb471b9e8bcff",
            "bd48929243444c8686df953f0df10ed8",
            "92bddb929abd4d21b67df56f4277a122",
            "062f6771ff084e10b8e21f79f378aa63",
            "c3b6f8be6679410fa53c428dfa0dcbdd",
            "f9fb841e7a1b4cedbcde4e8b0e818033",
            "a714a462b6c94548b55b10764da93c02",
            "95c1b3cf27ee4f72b4653a36254690c7",
            "a48bf200347f4d00b42ade06b38ed3a0",
            "fb719219e29744c6ad3c7700b0c387e3",
            "471d0f1548c94902819d86454bf4464d",
            "3808be62408740a99046d41f0ba7e9d1",
            "ba601c378b364ccfa8753c8dae4e98d3",
            "293386d2bbb84d99a414f1d94460f31a",
            "8d5136530b2144e08ef8e390c77d06c4",
            "eb61c5a99809443e8d54c46b6776d646",
            "b152dfc2de2d4671a9e8980575fa6900",
            "d5d33ace83484681a6e757c3bcb85a54",
            "aa5d247649e043d0b68c45bee68b1103",
            "24b3807a1fc645c0ad35cec3aa2b510b",
            "36ab3f9705fa49e78527073fe33729f5",
            "3d7a6d54a61c48cfb119eb72bf8faf7f",
            "a206fe07237c481e9ac4bce587630ba1",
            "2badb82f674c42d4b6edb52e3df4b10d"
          ]
        },
        "id": "D9rP6hSh_3Tf",
        "outputId": "127d68fc-3f45-4212-cff2-fcaff116e4f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-fd05778fe00e77d9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-fd05778fe00e77d9/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ef3e3c038374166940afa698d5c98a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92bddb929abd4d21b67df56f4277a122",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-fd05778fe00e77d9/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "293386d2bbb84d99a414f1d94460f31a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('text', \n",
        "                       data_files={'train': ['/content/OrientalismProject/descartes.txt',\n",
        "                                             '/content/OrientalismProject/david_hume.txt',\n",
        "                                             '/content/OrientalismProject/kant_critic_of_pure_reason',\n",
        "                                             '/content/OrientalismProject/david_hume.txt',\n",
        "                                             '/content/OrientalismProject/kant_fundamental_principles.txt',\n",
        "                                             '/content/OrientalismProject/locke_an_essay_concerning_human_understanding.txt']}\n",
        "                       )\n",
        "dataset.save_to_disk('/content/dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_v_ITvTHH2s",
        "outputId": "dac9c366-f183-44df-df10-7ece621c15ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ['conversation of other men teaches us; to which may be added as the',\n",
              "  'fourth, the reading, not of all books, but especially of such as',\n",
              "  'have been written by persons capable of conveying proper',\n",
              "  'instruction, for it is a species of conversation we hold with their',\n",
              "  'authors. And it seems to me that all the wisdom we in ordinary',\n",
              "  'possess is acquired only in these four ways; for I do not class',\n",
              "  'divine revelation among them, because it does not conduct us by',\n",
              "  'degrees, but elevates us at once to an infallible faith.',\n",
              "  '',\n",
              "  'There have been, indeed, in all ages great minds who endeavoured to']}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][100:110]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlPIUIFi8Gb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09s_xqfUjzGD"
      },
      "outputs": [],
      "source": [
        "def merge_texts(paths):\n",
        "  all_texts = ''\n",
        "  for path in paths:\n",
        "    all_texts += open('/content/' + path, 'r').read()\n",
        "  return all_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WrKzL8Di_W0",
        "outputId": "c1558397-1c1a-4ac1-8986-ae75d3326159"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['OrientalismProject/locke_an_essay_concerning_human_understanding.txt',\n",
              " 'OrientalismProject/kant_fundamental_principles.txt',\n",
              " 'OrientalismProject/descartes.txt',\n",
              " 'OrientalismProject/david_hume.txt',\n",
              " 'OrientalismProject/kant_critic_of_pure_reason.txt']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paths = [str(x) for x in Path(\".\").glob('**/*.txt')]\n",
        "paths.remove('requirements.txt')\n",
        "paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JexZE0TCk3sx"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/dataset/'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "  os.mkdirs(dataset_path)\n",
        "\n",
        "file = open(dataset_path + 'all_texts.txt', 'w')\n",
        "file.write(merge_texts(paths))\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-gbKTm2g1F2"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/model'\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jogLehCy7jm-",
        "outputId": "071620ef-111f-42b9-9cb2-ef958bc32643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/30/2021 20:46:26 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "11/30/2021 20:46:26 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/model/runs/Nov30_20-46-26_82309a879d01,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=/content/model,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=2,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/model,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "11/30/2021 20:46:27 - WARNING - datasets.builder - Using custom data configuration default-d2f94e11d9457306\n",
            "11/30/2021 20:46:27 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
            "100% 1/1 [00:00<00:00, 6678.83it/s]\n",
            "11/30/2021 20:46:27 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "11/30/2021 20:46:27 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 1/1 [00:00<00:00, 782.67it/s]\n",
            "11/30/2021 20:46:27 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "11/30/2021 20:46:27 - INFO - datasets.builder - Generating split train\n",
            "11/30/2021 20:46:27 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 585.88it/s]\n",
            "11/30/2021 20:46:28 - WARNING - datasets.builder - Using custom data configuration default-d2f94e11d9457306\n",
            "11/30/2021 20:46:28 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "11/30/2021 20:46:28 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "11/30/2021 20:46:28 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "11/30/2021 20:46:28 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "11/30/2021 20:46:29 - WARNING - datasets.builder - Using custom data configuration default-d2f94e11d9457306\n",
            "11/30/2021 20:46:29 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "11/30/2021 20:46:29 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "11/30/2021 20:46:29 - WARNING - datasets.builder - Reusing dataset text (/root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "11/30/2021 20:46:29 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5\n",
            "[INFO|file_utils.py:1807] 2021-11-30 20:46:30,773 >> https://huggingface.co/gpt2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpr3_ircmi\n",
            "Downloading: 100% 665/665 [00:00<00:00, 450kB/s]\n",
            "[INFO|file_utils.py:1811] 2021-11-30 20:46:31,525 >> storing https://huggingface.co/gpt2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|file_utils.py:1819] 2021-11-30 20:46:31,525 >> creating metadata file for /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:602] 2021-11-30 20:46:31,525 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:639] 2021-11-30 20:46:31,526 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:344] 2021-11-30 20:46:32,276 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:602] 2021-11-30 20:46:33,772 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:639] 2021-11-30 20:46:33,773 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1807] 2021-11-30 20:46:35,279 >> https://huggingface.co/gpt2/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpbz747_5z\n",
            "Downloading: 100% 0.99M/0.99M [00:01<00:00, 954kB/s]\n",
            "[INFO|file_utils.py:1811] 2021-11-30 20:46:37,133 >> storing https://huggingface.co/gpt2/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|file_utils.py:1819] 2021-11-30 20:46:37,133 >> creating metadata file for /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|file_utils.py:1807] 2021-11-30 20:46:37,878 >> https://huggingface.co/gpt2/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_mzjcsuw\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 627kB/s]\n",
            "[INFO|file_utils.py:1811] 2021-11-30 20:46:39,545 >> storing https://huggingface.co/gpt2/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1819] 2021-11-30 20:46:39,545 >> creating metadata file for /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1807] 2021-11-30 20:46:40,290 >> https://huggingface.co/gpt2/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpu87p0lkk\n",
            "Downloading: 100% 1.29M/1.29M [00:01<00:00, 1.23MB/s]\n",
            "[INFO|file_utils.py:1811] 2021-11-30 20:46:42,150 >> storing https://huggingface.co/gpt2/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|file_utils.py:1819] 2021-11-30 20:46:42,150 >> creating metadata file for /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-30 20:46:44,401 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-30 20:46:44,401 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-30 20:46:44,401 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-30 20:46:44,402 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-30 20:46:44,402 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-30 20:46:44,402 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:602] 2021-11-30 20:46:45,901 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:639] 2021-11-30 20:46:45,902 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1807] 2021-11-30 20:46:46,736 >> https://huggingface.co/gpt2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpotoqppek\n",
            "Downloading: 100% 523M/523M [00:13<00:00, 39.8MB/s]\n",
            "[INFO|file_utils.py:1811] 2021-11-30 20:47:00,603 >> storing https://huggingface.co/gpt2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|file_utils.py:1819] 2021-11-30 20:47:00,603 >> creating metadata file for /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:1352] 2021-11-30 20:47:00,603 >> loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:1619] 2021-11-30 20:47:02,634 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1628] 2021-11-30 20:47:02,634 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Running tokenizer on dataset:   0% 0/56 [00:00<?, ?ba/s]11/30/2021 20:47:02 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-5a62cedbbd787c7e.arrow\n",
            "Running tokenizer on dataset: 100% 56/56 [00:02<00:00, 20.87ba/s]\n",
            "Running tokenizer on dataset:   0% 0/3 [00:00<?, ?ba/s]11/30/2021 20:47:05 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-5cbc54fc173a888d.arrow\n",
            "Running tokenizer on dataset: 100% 3/3 [00:00<00:00, 29.32ba/s]\n",
            "Grouping texts in chunks of 512:   0% 0/56 [00:00<?, ?ba/s]11/30/2021 20:47:05 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-500ade618b1c25f8.arrow\n",
            "Grouping texts in chunks of 512: 100% 56/56 [00:01<00:00, 52.80ba/s]\n",
            "Grouping texts in chunks of 512:   0% 0/3 [00:00<?, ?ba/s]11/30/2021 20:47:06 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-d2f94e11d9457306/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-b8eb8fdbbef4ca5b.arrow\n",
            "Grouping texts in chunks of 512: 100% 3/3 [00:00<00:00, 63.00ba/s]\n",
            "[INFO|trainer.py:1196] 2021-11-30 20:47:17,060 >> ***** Running training *****\n",
            "[INFO|trainer.py:1197] 2021-11-30 20:47:17,060 >>   Num examples = 1462\n",
            "[INFO|trainer.py:1198] 2021-11-30 20:47:17,060 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1199] 2021-11-30 20:47:17,060 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:1200] 2021-11-30 20:47:17,060 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "[INFO|trainer.py:1201] 2021-11-30 20:47:17,060 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1202] 2021-11-30 20:47:17,060 >>   Total optimization steps = 2193\n",
            "{'loss': 3.3955, 'learning_rate': 3.860009119927041e-05, 'epoch': 0.68}\n",
            " 23% 500/2193 [05:24<18:27,  1.53it/s][INFO|trainer.py:2003] 2021-11-30 20:52:41,856 >> Saving model checkpoint to /content/model/checkpoint-500\n",
            "[INFO|configuration_utils.py:423] 2021-11-30 20:52:41,857 >> Configuration saved in /content/model/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1070] 2021-11-30 20:52:43,398 >> Model weights saved in /content/model/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-30 20:52:43,399 >> tokenizer config file saved in /content/model/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2049] 2021-11-30 20:52:43,399 >> Special tokens file saved in /content/model/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 3.1513, 'learning_rate': 2.7200182398540814e-05, 'epoch': 1.37}\n",
            " 46% 1000/2193 [10:56<12:58,  1.53it/s][INFO|trainer.py:2003] 2021-11-30 20:58:13,610 >> Saving model checkpoint to /content/model/checkpoint-1000\n",
            "[INFO|configuration_utils.py:423] 2021-11-30 20:58:13,611 >> Configuration saved in /content/model/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1070] 2021-11-30 20:58:15,157 >> Model weights saved in /content/model/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-30 20:58:15,158 >> tokenizer config file saved in /content/model/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2049] 2021-11-30 20:58:15,158 >> Special tokens file saved in /content/model/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 3.0556, 'learning_rate': 1.580027359781122e-05, 'epoch': 2.05}\n",
            " 68% 1500/2193 [16:26<07:26,  1.55it/s][INFO|trainer.py:2003] 2021-11-30 21:03:43,153 >> Saving model checkpoint to /content/model/checkpoint-1500\n",
            "[INFO|configuration_utils.py:423] 2021-11-30 21:03:43,154 >> Configuration saved in /content/model/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:1070] 2021-11-30 21:03:44,820 >> Model weights saved in /content/model/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-30 21:03:44,821 >> tokenizer config file saved in /content/model/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2049] 2021-11-30 21:03:44,821 >> Special tokens file saved in /content/model/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 2.9598, 'learning_rate': 4.400364797081624e-06, 'epoch': 2.74}\n",
            " 91% 2000/2193 [21:55<02:04,  1.55it/s][INFO|trainer.py:2003] 2021-11-30 21:09:12,509 >> Saving model checkpoint to /content/model/checkpoint-2000\n",
            "[INFO|configuration_utils.py:423] 2021-11-30 21:09:12,510 >> Configuration saved in /content/model/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:1070] 2021-11-30 21:09:14,222 >> Model weights saved in /content/model/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-30 21:09:14,223 >> tokenizer config file saved in /content/model/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2049] 2021-11-30 21:09:14,223 >> Special tokens file saved in /content/model/checkpoint-2000/special_tokens_map.json\n",
            "100% 2193/2193 [24:06<00:00,  1.55it/s][INFO|trainer.py:1417] 2021-11-30 21:11:23,271 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1446.2404, 'train_samples_per_second': 3.033, 'train_steps_per_second': 1.516, 'train_loss': 3.124418871836525, 'epoch': 3.0}\n",
            "100% 2193/2193 [24:06<00:00,  1.52it/s]\n",
            "[INFO|trainer.py:2003] 2021-11-30 21:11:23,303 >> Saving model checkpoint to /content/model\n",
            "[INFO|configuration_utils.py:423] 2021-11-30 21:11:23,304 >> Configuration saved in /content/model/config.json\n",
            "[INFO|modeling_utils.py:1070] 2021-11-30 21:11:24,824 >> Model weights saved in /content/model/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-30 21:11:24,824 >> tokenizer config file saved in /content/model/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2049] 2021-11-30 21:11:24,824 >> Special tokens file saved in /content/model/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     3.1244\n",
            "  train_runtime            = 0:24:06.24\n",
            "  train_samples            =       1462\n",
            "  train_samples_per_second =      3.033\n",
            "  train_steps_per_second   =      1.516\n",
            "11/30/2021 21:11:24 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:2248] 2021-11-30 21:11:24,981 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2250] 2021-11-30 21:11:24,981 >>   Num examples = 81\n",
            "[INFO|trainer.py:2253] 2021-11-30 21:11:24,981 >>   Batch size = 8\n",
            "100% 11/11 [00:07<00:00,  1.46it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_loss               =     3.2848\n",
            "  eval_runtime            = 0:00:07.55\n",
            "  eval_samples            =         81\n",
            "  eval_samples_per_second =     10.727\n",
            "  eval_steps_per_second   =      1.457\n",
            "  perplexity              =    26.7028\n",
            "[INFO|modelcard.py:449] 2021-11-30 21:11:33,337 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ],
      "source": [
        "!python run_clm.py \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --train_file /content/dataset/all_texts.txt \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --block_size 512 \\\n",
        "  --output_dir /content/model \\\n",
        "  --per_device_train_batch_size 2 \\\n",
        "  --overwrite_output_dir "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzdJwJzj77_c"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Named entity recognition pipeline, passing in a specific model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWV7B8c9QO-K"
      },
      "outputs": [],
      "source": [
        "BEGGING_TEXT = \"We generally gather knowledge with the help of some source of justification. Historically justification sometimes under such names as “reason to believe”, “evidence”. Now, epistemology questions the very foundation of justification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXQ3_G2atRFt"
      },
      "outputs": [],
      "source": [
        "BEGGING_TEXT2 = \"Epistemology is\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCwB4w_sBoAl",
        "outputId": "a10a0537-d91c-47c0-93e1-efdbe1919f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "text = pipeline(BEGGING_TEXT2, max_length=200)[0]['generated_text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cQAG5Zgxdlpr",
        "outputId": "7147f8fc-a94d-4195-903a-e9759be6d487"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Epistemology is (according to the first general principle) a conception of a necessary necessity—it cannot be given how absolutely impossible we conceive it to be the cause of a phenomena. Consequently, an object of possibility is not a part of our conception, but an empirical empirical notion of phenomena, that is to say, we find it in the empirical nature of our conception in general—it is always empirical (although a purely internal representation—in which case it does not make cognitions, which is only the mode of cognition that is possible) and is always possible.  As the conception of a thing in general does not apply to a phenomenon through which we can take something for an object, it cannot be given how absolutely impossible it should be if I could not give a cause, for example, how absolutely impossible, I could only form the conception of my present state, that is, of causality in general'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_list = list(text)\n",
        "while '\\n' in generated_list:\n",
        "  generated_list[generated_list.index('\\n')] = ' '\n",
        "\"\".join(generated_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l5sSw5BzgWY"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Epistemology is, by no means, to be taken\\nadvantage of as an essential and necessary principle: for any particular\\nmanifesto would not deserve the appellation'metaphysical', inasmuch as it were\\npossible to prove the unity of all intelligences, though\\nit would be absurd to employ it as a regulative principle. The\\nmetaphysic of religion is therefore a very narrow one, which has to do\\nwith the possibility or impossibility of any particular science:\\nand, as we shall observe, the ideal of the common understanding must\\nnot be, as appears frequently in it, based on the archetypes of the archetypes\\nof reason itself; while the philosophy of reason, on the other hand,\\ncannot (as has already been shown) have to do with the archetypes of\\nreason alone. The conception of a world in which reason was the\\nsoul, and of the existence of an intelligible being\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaQkBzMDzoTj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Importing_clm_run.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsnWO0pIGGBPPF66xsSnNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "062f6771ff084e10b8e21f79f378aa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c1b3cf27ee4f72b4653a36254690c7",
            "placeholder": "​",
            "style": "IPY_MODEL_a48bf200347f4d00b42ade06b38ed3a0",
            "value": "100%"
          }
        },
        "22bb77f37463433986f3e0a3c4c8c3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b3807a1fc645c0ad35cec3aa2b510b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "293386d2bbb84d99a414f1d94460f31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d5136530b2144e08ef8e390c77d06c4",
              "IPY_MODEL_eb61c5a99809443e8d54c46b6776d646",
              "IPY_MODEL_b152dfc2de2d4671a9e8980575fa6900"
            ],
            "layout": "IPY_MODEL_d5d33ace83484681a6e757c3bcb85a54"
          }
        },
        "2badb82f674c42d4b6edb52e3df4b10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33b9e9b72f0349eb94aba5e8ccc2abe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8343355c15e4719aefa092cca8c4330",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2b1157acf544098abf2bf951d330539",
            "value": 1
          }
        },
        "36ab3f9705fa49e78527073fe33729f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3808be62408740a99046d41f0ba7e9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d7a6d54a61c48cfb119eb72bf8faf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "409d74549cfc411c9208241493fcb78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ae36ae1334641cb919fb471b9e8bcff",
            "placeholder": "​",
            "style": "IPY_MODEL_bd48929243444c8686df953f0df10ed8",
            "value": " 1/1 [00:00&lt;00:00, 22.85it/s]"
          }
        },
        "4151f8bc9ffa4be1accae3030131df29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76cab0b69cb7469fa8a9521332e7b0af",
            "placeholder": "​",
            "style": "IPY_MODEL_bb6ffdb0b81b443681d2e8194d03d569",
            "value": "100%"
          }
        },
        "471d0f1548c94902819d86454bf4464d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ae36ae1334641cb919fb471b9e8bcff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76cab0b69cb7469fa8a9521332e7b0af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5136530b2144e08ef8e390c77d06c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5d247649e043d0b68c45bee68b1103",
            "placeholder": "​",
            "style": "IPY_MODEL_24b3807a1fc645c0ad35cec3aa2b510b",
            "value": "100%"
          }
        },
        "8ef3e3c038374166940afa698d5c98a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4151f8bc9ffa4be1accae3030131df29",
              "IPY_MODEL_33b9e9b72f0349eb94aba5e8ccc2abe2",
              "IPY_MODEL_409d74549cfc411c9208241493fcb78a"
            ],
            "layout": "IPY_MODEL_22bb77f37463433986f3e0a3c4c8c3cc"
          }
        },
        "92bddb929abd4d21b67df56f4277a122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_062f6771ff084e10b8e21f79f378aa63",
              "IPY_MODEL_c3b6f8be6679410fa53c428dfa0dcbdd",
              "IPY_MODEL_f9fb841e7a1b4cedbcde4e8b0e818033"
            ],
            "layout": "IPY_MODEL_a714a462b6c94548b55b10764da93c02"
          }
        },
        "95c1b3cf27ee4f72b4653a36254690c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a206fe07237c481e9ac4bce587630ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b1157acf544098abf2bf951d330539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a48bf200347f4d00b42ade06b38ed3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a714a462b6c94548b55b10764da93c02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5d247649e043d0b68c45bee68b1103": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b152dfc2de2d4671a9e8980575fa6900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a206fe07237c481e9ac4bce587630ba1",
            "placeholder": "​",
            "style": "IPY_MODEL_2badb82f674c42d4b6edb52e3df4b10d",
            "value": " 1/1 [00:00&lt;00:00, 20.52it/s]"
          }
        },
        "ba601c378b364ccfa8753c8dae4e98d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb6ffdb0b81b443681d2e8194d03d569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd48929243444c8686df953f0df10ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b6f8be6679410fa53c428dfa0dcbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb719219e29744c6ad3c7700b0c387e3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_471d0f1548c94902819d86454bf4464d",
            "value": 1
          }
        },
        "d5d33ace83484681a6e757c3bcb85a54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8343355c15e4719aefa092cca8c4330": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb61c5a99809443e8d54c46b6776d646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36ab3f9705fa49e78527073fe33729f5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d7a6d54a61c48cfb119eb72bf8faf7f",
            "value": 1
          }
        },
        "f9fb841e7a1b4cedbcde4e8b0e818033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3808be62408740a99046d41f0ba7e9d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ba601c378b364ccfa8753c8dae4e98d3",
            "value": " 1/1 [00:00&lt;00:00, 12.20it/s]"
          }
        },
        "fb719219e29744c6ad3c7700b0c387e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}